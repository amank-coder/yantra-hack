Title: Machine Learning Tutorial Python - 5: Save Model Using Joblib And Pickle
we will look into two different approaches of saving a trend model to a file which you can use later on to load the model from a file into memory and use that to make actual predictions solving a problem using machine learning consists of two steps typically the first step is training a model using your training data set and the second step is to ask your questions to the trained model which sort of looks like a human brain and that will give you the answers often the size of the training data set is pretty huge because as the size increases your model becomes more accurate it is like if you are doing a football training and if you train yourself more and more you become more and more better at your football game and when your training data set is so huge often it is in like gigabytes the training step becomes more time consuming if you save the train model to a file you can later on use that same model to make the actual prediction so you don't need to train it every time you want to ask these questions right so if you have it saved to a file now i don't have a training step here and i can directly ask questions so that's what we're going to look into today we'll write a python code to save that model to a file here i have a jupyter notebook which i used in my first tutorial of linear regression of predicting home prices the code here is pretty straightforward i am loading home prices from my csv file and then using linear regression to make the actual prediction and here it's saying that 5000 square feet home is gonna cost me 859 000 so let's use python's pickle module now you guys might be aware about pickle module already it allows you to serialize your python object into a file so here i will use the file so i'll first say with open model pickle and i'm going to write binary data hence i'm using wb mode in the file [Music] so first i am opening a file and then what i will do is i will say pickle.dump dump my model into this file when i run this what actually happens is in my working directory it created this model pickle file which if i open in my notepad looks like this this is some gibberish and it is expected to be gibberish because it because it's a binary file okay you actually don't need to care about the content here uh but what you need to know is your model is saved into a file now now you can use the same model here so what i can do is here i can say model is equal to pickle dump load the file okay so again i have to open the file pointer so it's the same file but this time i'm using it in a read mode and it's a binary for file hence i have supplied b here now i have my model i will just say mp so now i have my model loaded from a file into a memory and mp is the object if i use now mp object to make the prediction okay i want to ask what is the price of my 5 000 square feet home then you can see that it will give me the same answer as i got it here at this step so this is beautiful because now i can supply this model file to a friend of mine and i can say okay here is my trained model or a trained brain go use it for your actual problem all right so you can ask the questions to this model and it will give the answers there is a second approach of saving model to a file which is using sk learns job lib so if you google sk learn model persistent you will find this link where escalant's document documentation shows how you can use joblib to do essentially the same thing so then if it is doing the same thing then what's the difference between pickle and joblib as per the documentation if your model consists of large numpy arrays then using joblib might be more efficient now i have not done any profiling myself but you can go ahead and do it on your own and figure out which one you want to use but usually people say that when you have a lot of numpy arrays job lib tends to be more efficient but essentially it gives you the same functionality so i will first import joblib in jupyter notebook you can hit tab and it will show you the autocomplete so here there is external modules from that i will import joblib now the difference between job lib api and pickle api is that job lib can take the file name directly so i have my model and i want to save that model to a file i will say model joblit when execute this it saved this model to this particular file and when i go to my working directory i will find this file here it is just updated right now 631 is the timestamp when i open that file into notepad i will again see some gibberish because this is also a binary file again you don't care about the content here what you need to know is your model is successfully saved and you can load that model using joblib.load give the file name in return you get your model object back and that model object you can use to make actual prediction and it gives you the same answer here what it is saving inside that binary file is different things such as for example if you look at coefficient the coefficient is same as what i got it here so it's saving all these essential pieces for your model okay that's all i had for this tutorial i don't have any exercise today but you can go ahead and save your model using joblib and pickle into a file and i have gone through linear regression models today but you can pretty much save any other kind of machine learning models using these two awesome modules

